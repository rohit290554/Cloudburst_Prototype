{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1ca934",
   "metadata": {},
   "source": [
    "# ðŸŒ©ï¸ Cloudburst Prediction Prototype (Noida)\n",
    "This notebook processes **ERA5, IMERG, DEM** data and builds a baseline ML model for cloudburst detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dbfbce",
   "metadata": {},
   "source": [
    "First Env check will perform.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "print(\"âœ… Python executable in use:\")\n",
    "print(sys.executable)\n",
    "print(\"âœ… Python version:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "env_name = os.environ.get(\"CONDA_DEFAULT_ENV\", \"Unknown\")\n",
    "print(f\"âœ… Active Conda environment: {env_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Checking packages for cloudburst_data (preprocessing) ===\")\n",
    "try:\n",
    "    import numpy, pandas, xarray, rasterio, geopandas, fiona, shapely\n",
    "    from osgeo import gdal\n",
    "\n",
    "    print(\"âœ… numpy:\", numpy.__version__)\n",
    "    print(\"âœ… pandas:\", pandas.__version__)\n",
    "    print(\"âœ… xarray:\", xarray.__version__)\n",
    "    print(\"âœ… rasterio:\", rasterio.__version__)\n",
    "    print(\"âœ… geopandas:\", geopandas.__version__)\n",
    "    print(\"âœ… fiona:\", fiona.__version__)\n",
    "    print(\"âœ… shapely:\", shapely.__version__)\n",
    "    print(\"âœ… GDAL:\", gdal.__version__)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Some preprocessing libraries not available:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== Checking DEM tools ===\")\n",
    "try:\n",
    "    import richdem\n",
    "    print(\"âœ… RichDEM available\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import whitebox\n",
    "        print(\"âš ï¸ RichDEM not found, but Whitebox available\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ Neither RichDEM nor Whitebox available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== Checking packages for cloudburst_ml (ML/DL) ===\")\n",
    "try:\n",
    "    import sklearn, xgboost\n",
    "    print(\"âœ… scikit-learn:\", sklearn.__version__)\n",
    "    print(\"âœ… xgboost:\", xgboost.__version__)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ ML libraries missing:\", e)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"âœ… PyTorch:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"   GPU:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ PyTorch not available:\", e)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"âœ… TensorFlow:\", tf.__version__, \"GPU available:\", tf.test.is_gpu_available())\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ TensorFlow not available:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af03ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1. Setup ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import richdem as rd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Paths\n",
    "ERA5_PATH_instant = \"data/data_raw/era5/data_stream-oper_stepType-instant.nc\"\n",
    "ERA5_PATH_accum = \"data/data_raw/era5/data_stream-oper_stepType-accum.nc\"\n",
    "IMERG_PATH = \"data/data_raw/imerg/3B-HHR.MS.MRG.3IMERG.20240701-S000000-E002959.0000.V07B.HDF5.nc4\"\n",
    "DEM_PATH = \"data/data_raw/dem/noida.tif\"\n",
    "\n",
    "os.makedirs(\"data/data_processed\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f65fc",
   "metadata": {},
   "source": [
    "This sub-step will verify ERA5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d098fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Change path to your file\n",
    "ERA5_file_instant = ERA5_PATH_instant\n",
    "ERA5_file_accum = ERA5_PATH_accum\n",
    "\n",
    "ds = xr.open_dataset(ERA5_file_instant)\n",
    "\n",
    "# Quick summary\n",
    "print(\"\\nðŸ”Ž Dataset Info:\")\n",
    "\n",
    "print(\"ðŸ“‚ Global Attributes:\")\n",
    "print(ds.attrs)\n",
    "\n",
    "print(\"\\nðŸ“ Dimensions:\")\n",
    "print(ds.dims)\n",
    "\n",
    "print(\"\\nðŸ“Š Variables:\")\n",
    "print(list(ds.data_vars))\n",
    "\n",
    "print(ds)\n",
    "\n",
    "ds.close()\n",
    "ds = xr.open_dataset(ERA5_file_accum)\n",
    "\n",
    "print(\"ðŸ“‚ Global Attributes:\")\n",
    "print(ds.attrs) \n",
    "\n",
    "print(\"\\nðŸ“Š Variables:\")\n",
    "print(list(ds.data_vars))\n",
    "ds.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb2f5d7",
   "metadata": {},
   "source": [
    "This sub-step will verify IMERG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c45217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change to your IMERG file path\n",
    "file_path = IMERG_PATH\n",
    "\n",
    "# Open dataset\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# --- Quick details ---\n",
    "print(\"ðŸ“‚ Global Attributes:\")\n",
    "print(ds.attrs)\n",
    "\n",
    "print(\"\\nðŸ“ Dimensions:\")\n",
    "print(ds.dims)\n",
    "\n",
    "print(\"\\nðŸ“Š Variables:\")\n",
    "print(list(ds.data_vars))\n",
    "\n",
    "print(\"\\nðŸ”Ž Dataset Info:\")\n",
    "print(ds)\n",
    "\n",
    "# --- Quick plot of precipitationCal ---\n",
    "if \"precipitationCal\" in ds.data_vars:\n",
    "    var = ds[\"precipitationCal\"].isel(time=0)  # pick first time step\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    var.plot(cmap=\"Blues\", cbar_kwargs={\"label\": \"Rainfall (mm/hr)\"})\n",
    "    plt.title(\"IMERG PrecipitationCal Snapshot (time=0)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nâš ï¸ 'precipitationCal' variable not found in this file.\")\n",
    "\n",
    "ds.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f8efb",
   "metadata": {},
   "source": [
    "This sub-step will verify DEM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "with rasterio.open(DEM_PATH) as dem:\n",
    "    print(\"DEM bounds:\", dem.bounds)\n",
    "    print(\"Resolution:\", dem.res)\n",
    "    print(\"Shape:\", dem.height, \"x\", dem.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Load ERA5 ===\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import richdem as rd\n",
    "\n",
    "# Paths to downloaded files\n",
    "instant_file = ERA5_PATH_instant\n",
    "accum_file   = ERA5_PATH_accum\n",
    "\n",
    "# Open datasets\n",
    "ds_instant = xr.open_dataset(instant_file)\n",
    "ds_accum   = xr.open_dataset(accum_file)\n",
    "\n",
    "# Merge them\n",
    "era5 = xr.merge([ds_instant, ds_accum])\n",
    "\n",
    "# Now select all variables\n",
    "era5_df = era5[[\"t2m\",\"d2m\",\"tp\",\"cape\",\"sp\"]].to_dataframe().reset_index()\n",
    "\n",
    "# Rename time column if needed\n",
    "if \"valid_time\" in era5_df.columns:\n",
    "    era5_df = era5_df.rename(columns={\"valid_time\": \"time\"})\n",
    "\n",
    "# Convert cftime to standard datetime\n",
    "era5_df[\"time\"] = era5_df[\"time\"].apply(lambda x: pd.Timestamp(x.isoformat()))\n",
    "\n",
    "era5_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Load IMERG ===\n",
    "imerg = xr.open_dataset(IMERG_PATH)\n",
    "print(imerg)\n",
    "\n",
    "# Resample to hourly mean\n",
    "imerg_hourly = imerg.resample(time=\"1h\").mean()\n",
    "imerg_hourly[\"cloudburst\"] = (imerg_hourly[\"precipitation\"] >= 50).astype(int)\n",
    "\n",
    "# Convert to DataFrame\n",
    "imerg_df = imerg_hourly[[\"precipitation\",\"cloudburst\"]].to_dataframe().reset_index()\n",
    "\n",
    "# Convert cftime to standard datetime\n",
    "imerg_df[\"time\"] = imerg_df[\"time\"].apply(lambda x: pd.Timestamp(x.isoformat()))\n",
    "\n",
    "imerg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73299ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Load DEM ===\n",
    "with rasterio.open(DEM_PATH) as src:\n",
    "    dem_array = src.read(1)\n",
    "    bounds = src.bounds\n",
    "    res = src.res\n",
    "    print(\"DEM bounds:\", bounds, \"Resolution:\", res)\n",
    "\n",
    "dem_rd = rd.LoadGDAL(DEM_PATH)\n",
    "slope_array = rd.TerrainAttribute(dem_rd, attrib='slope_degrees')\n",
    "\n",
    "# Quick plots\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "axes[0].imshow(dem_array, cmap='terrain')\n",
    "axes[0].set_title(\"Elevation (m)\")\n",
    "axes[1].imshow(slope_array, cmap='inferno')\n",
    "axes[1].set_title(\"Slope (degrees)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Merge ERA5 + IMERG ===\n",
    "merged = pd.merge(era5_df, imerg_df, on=\"time\", how=\"inner\")\n",
    "\n",
    "# Add average DEM features (for Noida region)\n",
    "merged[\"elevation\"] = np.nanmean(dem_array)\n",
    "merged[\"slope\"] = np.nanmean(slope_array)\n",
    "\n",
    "print(merged.head())\n",
    "print(\"Dataset shape:\", merged.shape)\n",
    "\n",
    "# Save to CSV\n",
    "merged.to_csv(\"data/data_processed/noida_training_dataset.csv\", index=False)\n",
    "print(\"âœ… Training dataset saved: data/data_processed/noida_training_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ebdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Train Baseline ML Model ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset (with time column preserved for plotting in Step 7)\n",
    "merged = pd.read_csv(\"data/data_processed/noida_training_dataset.csv\")\n",
    "\n",
    "# Ensure time is datetime\n",
    "if \"time\" in merged.columns:\n",
    "    merged[\"time\"] = pd.to_datetime(merged[\"time\"], errors=\"coerce\")\n",
    "\n",
    "# Features and target\n",
    "X = merged[[\"t2m\", \"d2m\", \"tp\", \"cape\", \"sp\", \"elevation\", \"slope\"]].fillna(0).astype(float)\n",
    "y = merged[\"cloudburst\"].fillna(0).astype(int)\n",
    "\n",
    "# Train-test split (handle single-class case gracefully)\n",
    "if y.nunique() > 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "# Train XGBoost classifier (binary classification mode)\n",
    "model = XGBClassifier(\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    objective=\"binary:logistic\",  # Binary classification\n",
    "    base_score=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n=== Model Evaluation ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=[0, 1]))\n",
    "\n",
    "# Save for Step 7 visualization\n",
    "model_df = merged.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Interactive Visualization: Actual vs Predicted Cloudburst + Threshold ===\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Add predicted cloudburst column from model\n",
    "merged[\"cloudburst_pred\"] = model.predict(X)\n",
    "\n",
    "# Create a new column for combined status\n",
    "def combined_status(row):\n",
    "    if row[\"cloudburst\"] == 1 and row[\"cloudburst_pred\"] == 1:\n",
    "        return \"True Positive\"\n",
    "    elif row[\"cloudburst\"] == 0 and row[\"cloudburst_pred\"] == 0:\n",
    "        return \"True Negative\"\n",
    "    elif row[\"cloudburst\"] == 0 and row[\"cloudburst_pred\"] == 1:\n",
    "        return \"False Positive\"\n",
    "    else:\n",
    "        return \"False Negative\"\n",
    "\n",
    "merged[\"status\"] = merged.apply(combined_status, axis=1)\n",
    "\n",
    "# Base scatter plot\n",
    "fig = px.scatter(\n",
    "    merged,\n",
    "    x=\"time\",\n",
    "    y=\"tp\",\n",
    "    color=\"status\",\n",
    "    labels={\n",
    "        \"tp\": \"Rainfall (tp mm/hr)\",\n",
    "        \"time\": \"Time\",\n",
    "        \"status\": \"Cloudburst Prediction Status\"\n",
    "    },\n",
    "    hover_data=[\"t2m\",\"d2m\",\"cape\",\"sp\",\"elevation\",\"slope\",\"cloudburst\",\"cloudburst_pred\"]\n",
    ")\n",
    "\n",
    "# Add threshold line at 50 mm/hr\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=merged[\"time\"],\n",
    "        y=[50]*len(merged),\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        name=\"Cloudburst threshold (50 mm/hr)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, line=dict(width=1, color='DarkSlateGrey')))\n",
    "fig.update_layout(\n",
    "    title=\"Actual vs Predicted Cloudburst Events (Interactive) with Threshold\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Rainfall (tp mm/hr)\",\n",
    "    hovermode=\"closest\"\n",
    ")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CD)",
   "language": "python",
   "name": "cloud_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
